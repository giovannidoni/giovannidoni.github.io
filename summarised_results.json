{
  "picked_headlines": [
    {
      "item_number": 1,
      "summary": "AdaSD: Hyperparameter-free LLM inference with speedup and minimal accuracy loss.",
      "link": "https://arxiv.org/abs/2512.11280",
      "reason_for_choice": "AdaSD offers a significant advancement in LLM inference, appealing to both engineers and managers by reducing complexity and improving efficiency."
    },
    {
      "item_number": 7,
      "summary": "Dora: Optimizes QoE in distributed edge AI, enhancing performance.",
      "link": "https://arxiv.org/abs/2512.10990",
      "reason_for_choice": "Dora's focus on distributed edge AI is crucial for product development, making it relevant for both technical and strategic stakeholders."
    }
  ],
  "digest": "- *ASR-KF-EGR* optimizes LLM inference by reducing memory usage without losing context, offering a practical solution for deployment. [Link](https://arxiv.org/abs/2512.11221)\n- *FutureWeaver* enhances compute allocation in multi-agent systems, improving collaboration and performance under budget constraints. [Link](https://arxiv.org/abs/2512.11213)\n- *Dynamic scheduling* improves GPU cluster utilization and reduces job starvation, outperforming static policies with innovative methods. [Link](https://arxiv.org/abs/2512.10980)\n- *HyperAdaLoRA* enhances LoRA training speed using hypernetworks for dynamic rank allocation, improving convergence without performance loss. [Link](https://arxiv.org/abs/2510.02630)\n- *Deep Learning--Accelerated Multi-Start Large Neighborhood Search* presents a novel hybrid approach using deep learning and metaheuristics for efficient freight bundling in logistics. [Link](https://arxiv.org/abs/2512.11187)\n- *Agent-Based Modular Learning* enhances multimodal emotion recognition in human-agent systems, improving efficiency and flexibility. [Link](https://arxiv.org/abs/2512.10975)\n- *Towards Privacy-Preserving Code Generation* evaluates Differential Privacy in CodeLLMs, showing it reduces memorization while maintaining code generation performance. [Link](https://arxiv.org/abs/2512.11482)\n- *CREW-WILDFIRE* benchmarks scalable multi-agent AI in complex wildfire scenarios, addressing key performance gaps. [Link](https://arxiv.org/abs/2507.05178)\n- *Benchmarking Automatic Speech Recognition Models* for 13 African languages reveals insights on model efficiency and data scaling in low-resource settings. [Link](https://arxiv.org/abs/2512.10968)\n- *ReCode* unifies planning and action in LLMs, enhancing decision granularity and efficiency through recursive code generation. [Link](https://arxiv.org/abs/2510.23564)"
}